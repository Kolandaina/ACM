{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29205bd9",
   "metadata": {},
   "source": [
    "# 回归算法的正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除warning警报\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 导入加载数据集的方法\n",
    "from sklearn.datasets import load_boston\n",
    "# 特征处理器\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# 导入数据集划分方法\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 加载数据集\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "# 查看数据集形状\n",
    "print(\"特征数据形状：\",X.shape)\n",
    "print(\"响应变量形状：\",y.shape)\n",
    "# 设置多项式的最高次数为3\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "poly.fit(X)\n",
    "X_ = poly.transform(X)\n",
    "# 查看特征处理之后的数据集形状\n",
    "print(\"特征数据形状：\",X_.shape)\n",
    "print(\"响应变量形状：\",y.shape)\n",
    "# 按照8：2的比例切割数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y,train_size=0.8)\n",
    "# 查看训练集形状\n",
    "print(\"训练集特征维度\", X_train.shape)\n",
    "print(\"训练集响应变量维度\", y_train.shape)\n",
    "print(\"测试集特征维度\", X_test.shape)\n",
    "print(\"测试集响应变量维度\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c42861",
   "metadata": {},
   "source": [
    "### 2.多项式回归模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a95bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入线性回归模型\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# 创建线性回归模型\n",
    "pr = LinearRegression()\n",
    "# 使用线性回归模型拟合训练集数据\n",
    "pr.fit(X_train, y_train)\n",
    "# 预测数据\n",
    "yhat1 = pr.predict(X_train)\n",
    "yhat2 = pr.predict(X_test)\n",
    "# 导入均方误差方法，并使用均方误差评估模型\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 计算训练集的均方误差\n",
    "MSE1 = mean_squared_error(y_train, yhat1)\n",
    "print(\"训练集均方误差\",MSE1)\n",
    "# 计算测试集的均方误差\n",
    "MSE2 = mean_squared_error(y_test, yhat2)\n",
    "print(\"测试集均方误差\",MSE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace71dfb",
   "metadata": {},
   "source": [
    "### 3.L2正则化：导入岭(Ridge)回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b5e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入岭回归模型\n",
    "from sklearn.linear_model import Ridge\n",
    "# 创建岭回归模型\n",
    "pr = Ridge(alpha=1e10)\n",
    "# 使用岭回归模型拟合训练集数据\n",
    "pr.fit(X_train, y_train)\n",
    "# 预测数据\n",
    "yhat1 = pr.predict(X_train)\n",
    "yhat2 = pr.predict(X_test)\n",
    "# 导入均方误差方法，并使用均方误差评估模型\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 计算训练集的均方误差\n",
    "MSE1 = mean_squared_error(y_train, yhat1)\n",
    "print(\"训练集均方误差\",MSE1)\n",
    "# 计算测试集的均方误差\n",
    "MSE2 = mean_squared_error(y_test, yhat2)\n",
    "print(\"测试集均方误差\",MSE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e68cb",
   "metadata": {},
   "source": [
    "### 4.L1正则化：导入套索(Lasso)回归\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入套索回归模型\n",
    "from sklearn.linear_model import Lasso\n",
    "# 创建套索回归模型\n",
    "lasso_reg = Lasso(alpha=1e10)\n",
    "# 使用套索回归模型拟合训练集数据\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "# 预测数据\n",
    "yhat1_lasso = lasso_reg.predict(X_train)\n",
    "yhat2_lasso = lasso_reg.predict(X_test)\n",
    "# 导入均方误差方法，并使用均方误差评估模型\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 计算训练集的均方误差\n",
    "MSE1_lasso = mean_squared_error(y_train, yhat1_lasso)\n",
    "print(\"套索回归训练集均方误差:\", MSE1_lasso)\n",
    "# 计算测试集的均方误差\n",
    "MSE2_lasso = mean_squared_error(y_test, yhat2_lasso)\n",
    "print(\"套索回归测试集均方误差:\", MSE2_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd02c55",
   "metadata": {},
   "source": [
    "### 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285771b2",
   "metadata": {},
   "source": [
    "#### 由上面结果看出，L2需要将惩罚系数alpha调到比较大才能防止模型过拟合，而L1惩罚系数不需要调太大就防止了过拟合。\n",
    "***\n",
    "#### 原因是：L1具有稀疏性（可以将某些特征的系数直接估计为0），因此可以进行特征选择，而L2则不具有稀疏性，因此不具有特征选择能力。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
